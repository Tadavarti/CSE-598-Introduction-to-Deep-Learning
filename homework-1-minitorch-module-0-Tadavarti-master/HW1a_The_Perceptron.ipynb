{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Copy of HW1a - The Perceptron",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vYiZq0X2oB5t"
      },
      "source": [
        "# **CSE 598 Introduction to Deep Learning**\n",
        "\n",
        "# **HW1a The Perceptron** (20 pt)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vGVmKzgG2Ium",
        "outputId": "d9396400-9c9e-4a13-a6f6-79382a2210b4"
      },
      "source": [
        "# Get the datasets\n",
        "!wget http://www.cse.unt.edu/~blanco/csce5218/hw1a/train.dat\n",
        "!wget http://www.cse.unt.edu/~blanco/csce5218/hw1a/test.dat"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-09-11 06:37:33--  http://www.cse.unt.edu/~blanco/csce5218/hw1a/train.dat\n",
            "Resolving www.cse.unt.edu (www.cse.unt.edu)... 129.120.151.91\n",
            "Connecting to www.cse.unt.edu (www.cse.unt.edu)|129.120.151.91|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 11244 (11K) [application/x-ns-proxy-autoconfig]\n",
            "Saving to: ‘train.dat’\n",
            "\n",
            "\rtrain.dat             0%[                    ]       0  --.-KB/s               \rtrain.dat           100%[===================>]  10.98K  --.-KB/s    in 0s      \n",
            "\n",
            "2021-09-11 06:37:33 (234 MB/s) - ‘train.dat’ saved [11244/11244]\n",
            "\n",
            "--2021-09-11 06:37:33--  http://www.cse.unt.edu/~blanco/csce5218/hw1a/test.dat\n",
            "Resolving www.cse.unt.edu (www.cse.unt.edu)... 129.120.151.91\n",
            "Connecting to www.cse.unt.edu (www.cse.unt.edu)|129.120.151.91|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2844 (2.8K) [application/x-ns-proxy-autoconfig]\n",
            "Saving to: ‘test.dat’\n",
            "\n",
            "test.dat            100%[===================>]   2.78K  --.-KB/s    in 0s      \n",
            "\n",
            "2021-09-11 06:37:33 (308 MB/s) - ‘test.dat’ saved [2844/2844]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A69DxPSc8vNs",
        "outputId": "1512bf45-5574-4381-97ef-06d332d28c9f"
      },
      "source": [
        "# Take a peek at the datasets\n",
        "!head train.dat\n",
        "!head test.dat"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A1\tA2\tA3\tA4\tA5\tA6\tA7\tA8\tA9\tA10\tA11\tA12\tA13\t\n",
            "1\t1\t0\t0\t0\t0\t0\t0\t1\t1\t0\t0\t1\t0\n",
            "0\t0\t1\t1\t0\t1\t1\t0\t0\t0\t0\t0\t1\t0\n",
            "0\t1\t0\t1\t1\t0\t1\t0\t1\t1\t1\t0\t1\t1\n",
            "0\t0\t1\t0\t0\t1\t0\t1\t0\t1\t1\t1\t1\t0\n",
            "0\t1\t0\t0\t0\t0\t0\t1\t1\t1\t1\t1\t1\t0\n",
            "0\t1\t1\t1\t0\t0\t0\t1\t0\t1\t1\t0\t1\t1\n",
            "0\t1\t1\t0\t0\t0\t1\t0\t0\t0\t0\t0\t1\t0\n",
            "0\t0\t0\t1\t1\t0\t1\t1\t1\t0\t0\t0\t1\t0\n",
            "0\t0\t0\t0\t0\t0\t1\t0\t1\t0\t1\t0\t1\t0\n",
            "A1\tA2\tA3\tA4\tA5\tA6\tA7\tA8\tA9\tA10\tA11\tA12\tA13\n",
            "1\t1\t1\t1\t0\t0\t1\t1\t0\t0\t0\t1\t1\t0\n",
            "0\t0\t0\t1\t0\t0\t1\t1\t0\t1\t0\t0\t1\t0\n",
            "0\t1\t1\t1\t0\t1\t1\t1\t1\t0\t0\t0\t1\t0\n",
            "0\t1\t1\t0\t1\t0\t1\t1\t1\t0\t1\t0\t1\t0\n",
            "0\t1\t0\t0\t0\t1\t0\t1\t0\t1\t0\t0\t1\t0\n",
            "0\t1\t1\t0\t0\t1\t1\t1\t1\t1\t1\t0\t1\t0\n",
            "0\t1\t1\t1\t0\t0\t1\t1\t0\t0\t0\t1\t1\t0\n",
            "0\t1\t0\t0\t1\t0\t0\t1\t1\t0\t1\t1\t1\t0\n",
            "1\t1\t1\t1\t0\t0\t1\t1\t0\t0\t0\t0\t1\t0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cXAsP_lw3QwJ"
      },
      "source": [
        "import math\n",
        "import itertools\n",
        "import re\n",
        "\n",
        "\n",
        "# Corpus reader, all columns but the last one are coordinates;\n",
        "#   the last column is the label\n",
        "def read_data(file_name):\n",
        "    f = open(file_name, 'r')\n",
        "\n",
        "    data = []\n",
        "    # Discard header line\n",
        "    f.readline()\n",
        "    for instance in f.readlines():\n",
        "        if not re.search('\\t', instance): continue\n",
        "        instance = list(map(int, instance.strip().split('\\t')))\n",
        "        # Add a dummy input so that w0 becomes the bias\n",
        "        instance = [-1] + instance\n",
        "        data += [instance]\n",
        "    return data\n",
        "\n",
        "\n",
        "def dot_product(array1, array2):\n",
        "    # You do not to write code like this, but get used to it\n",
        "    return sum([w * x for w, x in zip(array1, array2)])\n",
        "\n",
        "\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + math.exp(-x))\n",
        "\n",
        "\n",
        "# Accuracy = percent of correct predictions\n",
        "def get_accuracy(weights, instances):\n",
        "    # You do not to write code like this, but get used to it\n",
        "    correct = sum([1 if predict(weights, instance) == instance[-1] else 0\n",
        "                   for instance in instances])\n",
        "    return correct * 100 / len(instances)\n",
        "\n",
        "\n",
        "# Predict a new instance; this is the definition of the perceptron\n",
        "def predict(weights, instance):\n",
        "    if sigmoid(dot_product(weights, instance)) >= 0.5:\n",
        "        return 1\n",
        "    return 0\n",
        "\n",
        "\n",
        "# Train a perceptron with instances\n",
        "#   and hyperparameters lr (leearning rate) and epochs\n",
        "# The implementation comes from the definition of the perceptron\n",
        "# Training consists on fitting the parameters\n",
        "#   The parameters are the weights, that's the only thing training is responsible to fit\n",
        "#     (recall that w0 is the bias, and w1..wn are the weights for each coordinate)\n",
        "#   Hyperparameters (lr and epochs) are given to the training algorithm\n",
        "# We are updating weights in the opposite direction of the gradient of the error,\n",
        "#   so with a \"decent\" lr we are guaranteed to reduce the error after each iteration.\n",
        "def train_perceptron(instances, lr, epochs):\n",
        "    weights = [0] * (len(instances[0])-1)\n",
        "    # weights = [0, 0, 0, ...,  0]\n",
        "\n",
        "    while epochs > 0:\n",
        "        for instance in instances:\n",
        "            in_value = dot_product(weights, instance)\n",
        "            output = sigmoid(in_value)\n",
        "            error = instance[-1] - output\n",
        "            for i in range(0, len(weights)):\n",
        "                weights[i] += lr * error * output * (1-output) * instance[i]\n",
        "\n",
        "        epochs -= 1\n",
        "        if epochs == 0:\n",
        "            break\n",
        "\n",
        "    return weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "50YvUza-BYQF",
        "outputId": "f611f05c-5477-41d7-8747-47ec881bb5af"
      },
      "source": [
        "instances_tr = read_data(\"train.dat\")\n",
        "instances_te = read_data(\"test.dat\")\n",
        "tr_percent = [5, 10, 25, 50, 75, 100]\n",
        "num_epochs = [5, 10, 20, 50, 100] \n",
        "lr = [0.005, 0.01, 0.05]  \n",
        "for i in tr_percent:\n",
        "  for j in num_epochs:\n",
        "    for k in lr:\n",
        "      new_instances=instances_tr[:len(instances_tr)*i//100]\n",
        "      weights = train_perceptron(new_instances,k, j)\n",
        "      accuracy = get_accuracy(weights, instances_te)\n",
        "      print(f\"#tr: {len(instances_tr):3}, epochs: {j:3}, learning rate: {k:.3f}; \"\n",
        "            f\"Accuracy (test, {len(instances_te)} instances): {accuracy:.1f}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "#tr: 400, epochs:   5, learning rate: 0.005; Accuracy (test, 100 instances): 68.0\n",
            "#tr: 400, epochs:   5, learning rate: 0.010; Accuracy (test, 100 instances): 68.0\n",
            "#tr: 400, epochs:   5, learning rate: 0.050; Accuracy (test, 100 instances): 68.0\n",
            "#tr: 400, epochs:  10, learning rate: 0.005; Accuracy (test, 100 instances): 68.0\n",
            "#tr: 400, epochs:  10, learning rate: 0.010; Accuracy (test, 100 instances): 68.0\n",
            "#tr: 400, epochs:  10, learning rate: 0.050; Accuracy (test, 100 instances): 68.0\n",
            "#tr: 400, epochs:  20, learning rate: 0.005; Accuracy (test, 100 instances): 68.0\n",
            "#tr: 400, epochs:  20, learning rate: 0.010; Accuracy (test, 100 instances): 68.0\n",
            "#tr: 400, epochs:  20, learning rate: 0.050; Accuracy (test, 100 instances): 68.0\n",
            "#tr: 400, epochs:  50, learning rate: 0.005; Accuracy (test, 100 instances): 68.0\n",
            "#tr: 400, epochs:  50, learning rate: 0.010; Accuracy (test, 100 instances): 68.0\n",
            "#tr: 400, epochs:  50, learning rate: 0.050; Accuracy (test, 100 instances): 68.0\n",
            "#tr: 400, epochs: 100, learning rate: 0.005; Accuracy (test, 100 instances): 68.0\n",
            "#tr: 400, epochs: 100, learning rate: 0.010; Accuracy (test, 100 instances): 68.0\n",
            "#tr: 400, epochs: 100, learning rate: 0.050; Accuracy (test, 100 instances): 64.0\n",
            "#tr: 400, epochs:   5, learning rate: 0.005; Accuracy (test, 100 instances): 68.0\n",
            "#tr: 400, epochs:   5, learning rate: 0.010; Accuracy (test, 100 instances): 68.0\n",
            "#tr: 400, epochs:   5, learning rate: 0.050; Accuracy (test, 100 instances): 68.0\n",
            "#tr: 400, epochs:  10, learning rate: 0.005; Accuracy (test, 100 instances): 68.0\n",
            "#tr: 400, epochs:  10, learning rate: 0.010; Accuracy (test, 100 instances): 68.0\n",
            "#tr: 400, epochs:  10, learning rate: 0.050; Accuracy (test, 100 instances): 68.0\n",
            "#tr: 400, epochs:  20, learning rate: 0.005; Accuracy (test, 100 instances): 68.0\n",
            "#tr: 400, epochs:  20, learning rate: 0.010; Accuracy (test, 100 instances): 68.0\n",
            "#tr: 400, epochs:  20, learning rate: 0.050; Accuracy (test, 100 instances): 68.0\n",
            "#tr: 400, epochs:  50, learning rate: 0.005; Accuracy (test, 100 instances): 68.0\n",
            "#tr: 400, epochs:  50, learning rate: 0.010; Accuracy (test, 100 instances): 68.0\n",
            "#tr: 400, epochs:  50, learning rate: 0.050; Accuracy (test, 100 instances): 71.0\n",
            "#tr: 400, epochs: 100, learning rate: 0.005; Accuracy (test, 100 instances): 68.0\n",
            "#tr: 400, epochs: 100, learning rate: 0.010; Accuracy (test, 100 instances): 68.0\n",
            "#tr: 400, epochs: 100, learning rate: 0.050; Accuracy (test, 100 instances): 69.0\n",
            "#tr: 400, epochs:   5, learning rate: 0.005; Accuracy (test, 100 instances): 68.0\n",
            "#tr: 400, epochs:   5, learning rate: 0.010; Accuracy (test, 100 instances): 68.0\n",
            "#tr: 400, epochs:   5, learning rate: 0.050; Accuracy (test, 100 instances): 68.0\n",
            "#tr: 400, epochs:  10, learning rate: 0.005; Accuracy (test, 100 instances): 68.0\n",
            "#tr: 400, epochs:  10, learning rate: 0.010; Accuracy (test, 100 instances): 68.0\n",
            "#tr: 400, epochs:  10, learning rate: 0.050; Accuracy (test, 100 instances): 67.0\n",
            "#tr: 400, epochs:  20, learning rate: 0.005; Accuracy (test, 100 instances): 68.0\n",
            "#tr: 400, epochs:  20, learning rate: 0.010; Accuracy (test, 100 instances): 68.0\n",
            "#tr: 400, epochs:  20, learning rate: 0.050; Accuracy (test, 100 instances): 70.0\n",
            "#tr: 400, epochs:  50, learning rate: 0.005; Accuracy (test, 100 instances): 68.0\n",
            "#tr: 400, epochs:  50, learning rate: 0.010; Accuracy (test, 100 instances): 68.0\n",
            "#tr: 400, epochs:  50, learning rate: 0.050; Accuracy (test, 100 instances): 74.0\n",
            "#tr: 400, epochs: 100, learning rate: 0.005; Accuracy (test, 100 instances): 68.0\n",
            "#tr: 400, epochs: 100, learning rate: 0.010; Accuracy (test, 100 instances): 71.0\n",
            "#tr: 400, epochs: 100, learning rate: 0.050; Accuracy (test, 100 instances): 77.0\n",
            "#tr: 400, epochs:   5, learning rate: 0.005; Accuracy (test, 100 instances): 68.0\n",
            "#tr: 400, epochs:   5, learning rate: 0.010; Accuracy (test, 100 instances): 68.0\n",
            "#tr: 400, epochs:   5, learning rate: 0.050; Accuracy (test, 100 instances): 71.0\n",
            "#tr: 400, epochs:  10, learning rate: 0.005; Accuracy (test, 100 instances): 68.0\n",
            "#tr: 400, epochs:  10, learning rate: 0.010; Accuracy (test, 100 instances): 68.0\n",
            "#tr: 400, epochs:  10, learning rate: 0.050; Accuracy (test, 100 instances): 77.0\n",
            "#tr: 400, epochs:  20, learning rate: 0.005; Accuracy (test, 100 instances): 68.0\n",
            "#tr: 400, epochs:  20, learning rate: 0.010; Accuracy (test, 100 instances): 68.0\n",
            "#tr: 400, epochs:  20, learning rate: 0.050; Accuracy (test, 100 instances): 78.0\n",
            "#tr: 400, epochs:  50, learning rate: 0.005; Accuracy (test, 100 instances): 67.0\n",
            "#tr: 400, epochs:  50, learning rate: 0.010; Accuracy (test, 100 instances): 74.0\n",
            "#tr: 400, epochs:  50, learning rate: 0.050; Accuracy (test, 100 instances): 78.0\n",
            "#tr: 400, epochs: 100, learning rate: 0.005; Accuracy (test, 100 instances): 74.0\n",
            "#tr: 400, epochs: 100, learning rate: 0.010; Accuracy (test, 100 instances): 78.0\n",
            "#tr: 400, epochs: 100, learning rate: 0.050; Accuracy (test, 100 instances): 76.0\n",
            "#tr: 400, epochs:   5, learning rate: 0.005; Accuracy (test, 100 instances): 68.0\n",
            "#tr: 400, epochs:   5, learning rate: 0.010; Accuracy (test, 100 instances): 68.0\n",
            "#tr: 400, epochs:   5, learning rate: 0.050; Accuracy (test, 100 instances): 74.0\n",
            "#tr: 400, epochs:  10, learning rate: 0.005; Accuracy (test, 100 instances): 68.0\n",
            "#tr: 400, epochs:  10, learning rate: 0.010; Accuracy (test, 100 instances): 68.0\n",
            "#tr: 400, epochs:  10, learning rate: 0.050; Accuracy (test, 100 instances): 78.0\n",
            "#tr: 400, epochs:  20, learning rate: 0.005; Accuracy (test, 100 instances): 68.0\n",
            "#tr: 400, epochs:  20, learning rate: 0.010; Accuracy (test, 100 instances): 70.0\n",
            "#tr: 400, epochs:  20, learning rate: 0.050; Accuracy (test, 100 instances): 79.0\n",
            "#tr: 400, epochs:  50, learning rate: 0.005; Accuracy (test, 100 instances): 74.0\n",
            "#tr: 400, epochs:  50, learning rate: 0.010; Accuracy (test, 100 instances): 78.0\n",
            "#tr: 400, epochs:  50, learning rate: 0.050; Accuracy (test, 100 instances): 78.0\n",
            "#tr: 400, epochs: 100, learning rate: 0.005; Accuracy (test, 100 instances): 78.0\n",
            "#tr: 400, epochs: 100, learning rate: 0.010; Accuracy (test, 100 instances): 80.0\n",
            "#tr: 400, epochs: 100, learning rate: 0.050; Accuracy (test, 100 instances): 77.0\n",
            "#tr: 400, epochs:   5, learning rate: 0.005; Accuracy (test, 100 instances): 68.0\n",
            "#tr: 400, epochs:   5, learning rate: 0.010; Accuracy (test, 100 instances): 68.0\n",
            "#tr: 400, epochs:   5, learning rate: 0.050; Accuracy (test, 100 instances): 69.0\n",
            "#tr: 400, epochs:  10, learning rate: 0.005; Accuracy (test, 100 instances): 68.0\n",
            "#tr: 400, epochs:  10, learning rate: 0.010; Accuracy (test, 100 instances): 69.0\n",
            "#tr: 400, epochs:  10, learning rate: 0.050; Accuracy (test, 100 instances): 76.0\n",
            "#tr: 400, epochs:  20, learning rate: 0.005; Accuracy (test, 100 instances): 69.0\n",
            "#tr: 400, epochs:  20, learning rate: 0.010; Accuracy (test, 100 instances): 70.0\n",
            "#tr: 400, epochs:  20, learning rate: 0.050; Accuracy (test, 100 instances): 80.0\n",
            "#tr: 400, epochs:  50, learning rate: 0.005; Accuracy (test, 100 instances): 73.0\n",
            "#tr: 400, epochs:  50, learning rate: 0.010; Accuracy (test, 100 instances): 77.0\n",
            "#tr: 400, epochs:  50, learning rate: 0.050; Accuracy (test, 100 instances): 80.0\n",
            "#tr: 400, epochs: 100, learning rate: 0.005; Accuracy (test, 100 instances): 77.0\n",
            "#tr: 400, epochs: 100, learning rate: 0.010; Accuracy (test, 100 instances): 80.0\n",
            "#tr: 400, epochs: 100, learning rate: 0.050; Accuracy (test, 100 instances): 80.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CBXkvaiQMohX"
      },
      "source": [
        "## Questions\n",
        "\n",
        "Answer the following questions. Include your implementation and the output for each question."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YCQ6BEk1CBlr"
      },
      "source": [
        "\n",
        "\n",
        "### Question 1\n",
        "\n",
        "In `train_perceptron(instances, lr, epochs)`, we have the follosing code:\n",
        "```\n",
        "in_value = dot_product(weights, instance)\n",
        "output = sigmoid(in_value)\n",
        "error = instance[-1] - output\n",
        "```\n",
        "\n",
        "Why don't we have the following code snippet instead?\n",
        "```\n",
        "output = predict(weights, instance)\n",
        "error = instance[-1] - output\n",
        "```\n",
        "\n",
        "#### TODO Add your answer here (text only)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fq-72WPNlBVt"
      },
      "source": [
        "As it is a linear classifier, it is unable to deal with nonlinear problems so we use below code snippet.\n",
        "\n",
        "in_value = dot_product(weights, instance)\n",
        "\n",
        "output = sigmoid(in_value)\n",
        "\n",
        "error = instance[-1] - output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JU3c3m6YL2rK"
      },
      "source": [
        "### Question 2\n",
        "Train the perceptron with the following hyperparameters and calculate the accuracy with the test dataset.\n",
        "\n",
        "```\n",
        "tr_percent = [5, 10, 25, 50, 75, 100] # percent of the training dataset to train with\n",
        "num_epochs = [5, 10, 20, 50, 100]              # number of epochs\n",
        "lr = [0.005, 0.01, 0.05]              # learning rate\n",
        "```\n",
        "\n",
        "TODO Write your code below and include the output of your code.\n",
        "The output should look like the following:\n",
        "```\n",
        "# tr:  20, epochs:   5, learning rate: 0.005; Accuracy (test, 100 instances): 68.0\n",
        "# tr:  20, epochs:  10, learning rate: 0.005; Accuracy (test, 100 instances): 68.0\n",
        "# tr:  20, epochs:  20, learning rate: 0.005; Accuracy (test, 100 instances): 68.0\n",
        "[and so on for all the combinations]\n",
        "```\n",
        "You will get different results with differet hyperparameters.\n",
        "\n",
        "#### TODO Add your answer here (code and output in the format above) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rVf_vIF5l5II",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c566087-016d-44e5-e057-6c786839493f"
      },
      "source": [
        "instances_tr = read_data(\"train.dat\")\n",
        "instances_te = read_data(\"test.dat\")\n",
        "tr_percent = [5, 10, 25, 50, 75, 100]\n",
        "num_epochs = [5, 10, 20, 50, 100] \n",
        "lr = [0.005, 0.01, 0.05]  \n",
        "for i in tr_percent:\n",
        "  for j in num_epochs:\n",
        "    for k in lr:\n",
        "      new_instances=instances_tr[:len(instances_tr)*i//100]\n",
        "      weights = train_perceptron(new_instances,k, j)\n",
        "      accuracy = get_accuracy(weights, instances_te)\n",
        "      print(f\"#tr: {len(instances_tr):3}, epochs: {j:3}, learning rate: {k:.3f}; \"\n",
        "            f\"Accuracy (test, {len(instances_te)} instances): {accuracy:.1f}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "#tr: 400, epochs:   5, learning rate: 0.005; Accuracy (test, 100 instances): 68.0\n",
            "#tr: 400, epochs:   5, learning rate: 0.010; Accuracy (test, 100 instances): 68.0\n",
            "#tr: 400, epochs:   5, learning rate: 0.050; Accuracy (test, 100 instances): 68.0\n",
            "#tr: 400, epochs:  10, learning rate: 0.005; Accuracy (test, 100 instances): 68.0\n",
            "#tr: 400, epochs:  10, learning rate: 0.010; Accuracy (test, 100 instances): 68.0\n",
            "#tr: 400, epochs:  10, learning rate: 0.050; Accuracy (test, 100 instances): 68.0\n",
            "#tr: 400, epochs:  20, learning rate: 0.005; Accuracy (test, 100 instances): 68.0\n",
            "#tr: 400, epochs:  20, learning rate: 0.010; Accuracy (test, 100 instances): 68.0\n",
            "#tr: 400, epochs:  20, learning rate: 0.050; Accuracy (test, 100 instances): 68.0\n",
            "#tr: 400, epochs:  50, learning rate: 0.005; Accuracy (test, 100 instances): 68.0\n",
            "#tr: 400, epochs:  50, learning rate: 0.010; Accuracy (test, 100 instances): 68.0\n",
            "#tr: 400, epochs:  50, learning rate: 0.050; Accuracy (test, 100 instances): 68.0\n",
            "#tr: 400, epochs: 100, learning rate: 0.005; Accuracy (test, 100 instances): 68.0\n",
            "#tr: 400, epochs: 100, learning rate: 0.010; Accuracy (test, 100 instances): 68.0\n",
            "#tr: 400, epochs: 100, learning rate: 0.050; Accuracy (test, 100 instances): 64.0\n",
            "#tr: 400, epochs:   5, learning rate: 0.005; Accuracy (test, 100 instances): 68.0\n",
            "#tr: 400, epochs:   5, learning rate: 0.010; Accuracy (test, 100 instances): 68.0\n",
            "#tr: 400, epochs:   5, learning rate: 0.050; Accuracy (test, 100 instances): 68.0\n",
            "#tr: 400, epochs:  10, learning rate: 0.005; Accuracy (test, 100 instances): 68.0\n",
            "#tr: 400, epochs:  10, learning rate: 0.010; Accuracy (test, 100 instances): 68.0\n",
            "#tr: 400, epochs:  10, learning rate: 0.050; Accuracy (test, 100 instances): 68.0\n",
            "#tr: 400, epochs:  20, learning rate: 0.005; Accuracy (test, 100 instances): 68.0\n",
            "#tr: 400, epochs:  20, learning rate: 0.010; Accuracy (test, 100 instances): 68.0\n",
            "#tr: 400, epochs:  20, learning rate: 0.050; Accuracy (test, 100 instances): 68.0\n",
            "#tr: 400, epochs:  50, learning rate: 0.005; Accuracy (test, 100 instances): 68.0\n",
            "#tr: 400, epochs:  50, learning rate: 0.010; Accuracy (test, 100 instances): 68.0\n",
            "#tr: 400, epochs:  50, learning rate: 0.050; Accuracy (test, 100 instances): 71.0\n",
            "#tr: 400, epochs: 100, learning rate: 0.005; Accuracy (test, 100 instances): 68.0\n",
            "#tr: 400, epochs: 100, learning rate: 0.010; Accuracy (test, 100 instances): 68.0\n",
            "#tr: 400, epochs: 100, learning rate: 0.050; Accuracy (test, 100 instances): 69.0\n",
            "#tr: 400, epochs:   5, learning rate: 0.005; Accuracy (test, 100 instances): 68.0\n",
            "#tr: 400, epochs:   5, learning rate: 0.010; Accuracy (test, 100 instances): 68.0\n",
            "#tr: 400, epochs:   5, learning rate: 0.050; Accuracy (test, 100 instances): 68.0\n",
            "#tr: 400, epochs:  10, learning rate: 0.005; Accuracy (test, 100 instances): 68.0\n",
            "#tr: 400, epochs:  10, learning rate: 0.010; Accuracy (test, 100 instances): 68.0\n",
            "#tr: 400, epochs:  10, learning rate: 0.050; Accuracy (test, 100 instances): 67.0\n",
            "#tr: 400, epochs:  20, learning rate: 0.005; Accuracy (test, 100 instances): 68.0\n",
            "#tr: 400, epochs:  20, learning rate: 0.010; Accuracy (test, 100 instances): 68.0\n",
            "#tr: 400, epochs:  20, learning rate: 0.050; Accuracy (test, 100 instances): 70.0\n",
            "#tr: 400, epochs:  50, learning rate: 0.005; Accuracy (test, 100 instances): 68.0\n",
            "#tr: 400, epochs:  50, learning rate: 0.010; Accuracy (test, 100 instances): 68.0\n",
            "#tr: 400, epochs:  50, learning rate: 0.050; Accuracy (test, 100 instances): 74.0\n",
            "#tr: 400, epochs: 100, learning rate: 0.005; Accuracy (test, 100 instances): 68.0\n",
            "#tr: 400, epochs: 100, learning rate: 0.010; Accuracy (test, 100 instances): 71.0\n",
            "#tr: 400, epochs: 100, learning rate: 0.050; Accuracy (test, 100 instances): 77.0\n",
            "#tr: 400, epochs:   5, learning rate: 0.005; Accuracy (test, 100 instances): 68.0\n",
            "#tr: 400, epochs:   5, learning rate: 0.010; Accuracy (test, 100 instances): 68.0\n",
            "#tr: 400, epochs:   5, learning rate: 0.050; Accuracy (test, 100 instances): 71.0\n",
            "#tr: 400, epochs:  10, learning rate: 0.005; Accuracy (test, 100 instances): 68.0\n",
            "#tr: 400, epochs:  10, learning rate: 0.010; Accuracy (test, 100 instances): 68.0\n",
            "#tr: 400, epochs:  10, learning rate: 0.050; Accuracy (test, 100 instances): 77.0\n",
            "#tr: 400, epochs:  20, learning rate: 0.005; Accuracy (test, 100 instances): 68.0\n",
            "#tr: 400, epochs:  20, learning rate: 0.010; Accuracy (test, 100 instances): 68.0\n",
            "#tr: 400, epochs:  20, learning rate: 0.050; Accuracy (test, 100 instances): 78.0\n",
            "#tr: 400, epochs:  50, learning rate: 0.005; Accuracy (test, 100 instances): 67.0\n",
            "#tr: 400, epochs:  50, learning rate: 0.010; Accuracy (test, 100 instances): 74.0\n",
            "#tr: 400, epochs:  50, learning rate: 0.050; Accuracy (test, 100 instances): 78.0\n",
            "#tr: 400, epochs: 100, learning rate: 0.005; Accuracy (test, 100 instances): 74.0\n",
            "#tr: 400, epochs: 100, learning rate: 0.010; Accuracy (test, 100 instances): 78.0\n",
            "#tr: 400, epochs: 100, learning rate: 0.050; Accuracy (test, 100 instances): 76.0\n",
            "#tr: 400, epochs:   5, learning rate: 0.005; Accuracy (test, 100 instances): 68.0\n",
            "#tr: 400, epochs:   5, learning rate: 0.010; Accuracy (test, 100 instances): 68.0\n",
            "#tr: 400, epochs:   5, learning rate: 0.050; Accuracy (test, 100 instances): 74.0\n",
            "#tr: 400, epochs:  10, learning rate: 0.005; Accuracy (test, 100 instances): 68.0\n",
            "#tr: 400, epochs:  10, learning rate: 0.010; Accuracy (test, 100 instances): 68.0\n",
            "#tr: 400, epochs:  10, learning rate: 0.050; Accuracy (test, 100 instances): 78.0\n",
            "#tr: 400, epochs:  20, learning rate: 0.005; Accuracy (test, 100 instances): 68.0\n",
            "#tr: 400, epochs:  20, learning rate: 0.010; Accuracy (test, 100 instances): 70.0\n",
            "#tr: 400, epochs:  20, learning rate: 0.050; Accuracy (test, 100 instances): 79.0\n",
            "#tr: 400, epochs:  50, learning rate: 0.005; Accuracy (test, 100 instances): 74.0\n",
            "#tr: 400, epochs:  50, learning rate: 0.010; Accuracy (test, 100 instances): 78.0\n",
            "#tr: 400, epochs:  50, learning rate: 0.050; Accuracy (test, 100 instances): 78.0\n",
            "#tr: 400, epochs: 100, learning rate: 0.005; Accuracy (test, 100 instances): 78.0\n",
            "#tr: 400, epochs: 100, learning rate: 0.010; Accuracy (test, 100 instances): 80.0\n",
            "#tr: 400, epochs: 100, learning rate: 0.050; Accuracy (test, 100 instances): 77.0\n",
            "#tr: 400, epochs:   5, learning rate: 0.005; Accuracy (test, 100 instances): 68.0\n",
            "#tr: 400, epochs:   5, learning rate: 0.010; Accuracy (test, 100 instances): 68.0\n",
            "#tr: 400, epochs:   5, learning rate: 0.050; Accuracy (test, 100 instances): 69.0\n",
            "#tr: 400, epochs:  10, learning rate: 0.005; Accuracy (test, 100 instances): 68.0\n",
            "#tr: 400, epochs:  10, learning rate: 0.010; Accuracy (test, 100 instances): 69.0\n",
            "#tr: 400, epochs:  10, learning rate: 0.050; Accuracy (test, 100 instances): 76.0\n",
            "#tr: 400, epochs:  20, learning rate: 0.005; Accuracy (test, 100 instances): 69.0\n",
            "#tr: 400, epochs:  20, learning rate: 0.010; Accuracy (test, 100 instances): 70.0\n",
            "#tr: 400, epochs:  20, learning rate: 0.050; Accuracy (test, 100 instances): 80.0\n",
            "#tr: 400, epochs:  50, learning rate: 0.005; Accuracy (test, 100 instances): 73.0\n",
            "#tr: 400, epochs:  50, learning rate: 0.010; Accuracy (test, 100 instances): 77.0\n",
            "#tr: 400, epochs:  50, learning rate: 0.050; Accuracy (test, 100 instances): 80.0\n",
            "#tr: 400, epochs: 100, learning rate: 0.005; Accuracy (test, 100 instances): 77.0\n",
            "#tr: 400, epochs: 100, learning rate: 0.010; Accuracy (test, 100 instances): 80.0\n",
            "#tr: 400, epochs: 100, learning rate: 0.050; Accuracy (test, 100 instances): 80.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OFB9MtwML24O"
      },
      "source": [
        "### Question 3\n",
        "Write a couple paragraphs interpreting the results with all the combinations of hyperparameters. Drawing a plot will probably help you make a point. In particular, answer the following:\n",
        "- Do you need to train with all the training dataset to get the highest accuracy with the test dataset?\n",
        "- How do you justify that training the second run obtains worse accuracy than the first one (despite the second one uses more training data)?\n",
        "   ```\n",
        "#tr: 100, epochs:  20, learning rate: 0.050; Accuracy (test, 100 instances): 71.0\n",
        "#tr: 200, epochs:  20, learning rate: 0.005; Accuracy (test, 100 instances): 68.0\n",
        "```\n",
        "- Can you get higher accuracy with additional hyperparameters (higher than `80.0`)?\n",
        "- Is it always worth training for more epochs (while keeping all other hyperparameters fixed)?\n",
        "\n",
        "#### TODO Add your answer here (code and text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ky6AhsuTmow0"
      },
      "source": [
        "1)Not necessarily. As we give different hyperparameters we can train data with  different accuracy rates as we see in question2.\n",
        "2)We have low epochs and lesser learning rate for the second hyperparameter so we have lesser accuracy than first one\n",
        "3)No As I tried in second question I havent received accuracy greater than 80 for any passed hyperparameters.\n",
        "4)Yes it is. As we train dataset to it highest accuracy we can get best prediction results and can learn more."
      ]
    }
  ]
}